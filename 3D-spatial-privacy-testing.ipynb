{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#sys.path.insert(0, \"../\")\n",
    "from info3d import *\n",
    "from nn_matchers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING the existing sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('point_collection/new_contiguous_point_collection.pickle','rb') as f: \n",
    "    new_contiguous_point_collection = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/new_complete_res5_4by5_descriptors.pickle','rb') as f:\n",
    "    descriptors = pickle.load(f)\n",
    "\n",
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "# We used a radius range of 0.25 to 5.0 in increments of 0.25\n",
    "radius_range = np.arange(0.5,1.6,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.1: Testing with Partial Spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Testing our partial samples: Raw spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " radius = 0.5: Done with 9 iterations. Time to match 18.464 seconds.\n",
      "   Error Rate: 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/jaybie/spatial-privacy/nn_matchers.py:510: FutureWarning: in the future insert will treat boolean arrays and array-likes as a boolean index instead of casting it to integer\n",
      "  good_matches_kp_idx = np.insert(good_matches[good_matches_ref_kp],True,good_matches_ref_kp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " radius = 0.5: Done with 19 iterations. Time to match 19.066 seconds.\n",
      "   Error Rate: 0.7894736842105263\n",
      " radius = 0.5: Done with 29 iterations. Time to match 18.684 seconds.\n",
      "   Error Rate: 0.793103448275862\n",
      " radius = 0.5: Done with 39 iterations. Time to match 18.210 seconds.\n",
      "   Error Rate: 0.7435897435897437\n",
      " radius = 0.5: Done with 49 iterations. Time to match 17.672 seconds.\n",
      "   Error Rate: 0.7755102040816326\n",
      "0.5 Error Rate: 0.78\n",
      " radius = 1.0: Done with 9 iterations. Time to match 44.307 seconds.\n",
      "   Error Rate: 0.3333333333333333\n",
      " radius = 1.0: Done with 19 iterations. Time to match 53.319 seconds.\n",
      "   Error Rate: 0.3684210526315789\n",
      " radius = 1.0: Done with 29 iterations. Time to match 57.353 seconds.\n",
      "   Error Rate: 0.27586206896551724\n",
      " radius = 1.0: Done with 39 iterations. Time to match 49.603 seconds.\n",
      "   Error Rate: 0.3076923076923077\n",
      " radius = 1.0: Done with 49 iterations. Time to match 51.456 seconds.\n",
      "   Error Rate: 0.3469387755102041\n",
      "1.0 Error Rate: 0.34\n",
      " radius = 1.5: Done with 9 iterations. Time to match 48.628 seconds.\n",
      "   Error Rate: 0.4444444444444444\n",
      " radius = 1.5: Done with 19 iterations. Time to match 55.074 seconds.\n",
      "   Error Rate: 0.3157894736842105\n",
      " radius = 1.5: Done with 29 iterations. Time to match 63.371 seconds.\n",
      "   Error Rate: 0.27586206896551724\n",
      " radius = 1.5: Done with 39 iterations. Time to match 56.509 seconds.\n",
      "   Error Rate: 0.28205128205128205\n",
      " radius = 1.5: Done with 49 iterations. Time to match 55.152 seconds.\n",
      "   Error Rate: 0.26530612244897955\n",
      "1.5 Error Rate: 0.26\n"
     ]
    }
   ],
   "source": [
    "for radius in radius_range:\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    with open('testing_samples/{}_partial_point_cloud.pickle'.format(radius), 'rb') as f:\n",
    "        partial_point_collection = pickle.load(f)\n",
    "        samples = len(partial_point_collection)\n",
    "        \n",
    "    partial_scores = []\n",
    "    \n",
    "    for obj_meta, partial_pointcloud, partial_triangles in partial_point_collection:\n",
    "        \n",
    "        # ROTATION\n",
    "        random_theta =  (2*np.pi)*np.random.random()# from [0, 2pi)\n",
    "        random_axis = np.random.choice(np.arange(0,3))\n",
    "        rotated_pointCloud = rotatePointCloud(partial_pointcloud, random_theta, random_axis)\n",
    "\n",
    "        # TRANSLATION\n",
    "        t_pointCloud = np.asarray(rotated_pointCloud)\n",
    "        random_tx_axis = np.random.choice(np.arange(0,3))\n",
    "        random_translation = np.random.random()\n",
    "        t_pointCloud[:,random_tx_axis] = t_pointCloud[:,random_tx_axis] + random_translation\n",
    "        t_triangles = np.asarray(partial_triangles)#-vertices_length\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        try:\n",
    "            p_descriptors, p_keypoints, p_d_c = getSpinImageDescriptors(\n",
    "                t_pointCloud,\n",
    "                down_resolution = 5,\n",
    "                cylindrical_quantization = [4,5]\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            print(\"Error getting descriptors of\",obj_meta)\n",
    "            print(\"Error Message:\",ex)\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # Resetting the diff_Ratio matrix\n",
    "        diff_scores = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "        diff_ratios = np.ones((p_descriptors.shape[0],len(descriptors)))\n",
    "        diff_indexs = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "\n",
    "        #print(diff_ratios.shape)\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        for i_r, ref_descriptor in enumerate(descriptors):\n",
    "\n",
    "            r_descriptors = ref_descriptor[1]\n",
    "            r_keypoints = ref_descriptor[2]\n",
    "\n",
    "            matching_range = np.arange(r_descriptors.shape[1])\n",
    "\n",
    "            try:    \n",
    "                f_nearestneighbor, diff = getMatches(p_descriptors,r_descriptors,2,range_to_match=matching_range)\n",
    "                diff = diff/np.amax(diff) # max-normalization of differences\n",
    "                diff_ratio = diff[:,0]/diff[:,1]\n",
    "                diff_ratios[:,i_r] = diff_ratio\n",
    "                diff_scores[:,i_r] = diff\n",
    "                diff_indexs[:,i_r] = f_nearestneighbor\n",
    "                \n",
    "                # Taking note of the matched keypoints\n",
    "                local_keypoint_matches.append([\n",
    "                    obj_meta,\n",
    "                    p_keypoints,\n",
    "                    r_keypoints[f_nearestneighbor[:,0]]\n",
    "                ])\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(rotation,\"Error Matching:\",ex)\n",
    "\n",
    "        # Accumulating the diff_ratio matrix for every partial (rotated) object\n",
    "        partial_scores.append([\n",
    "            obj_meta,\n",
    "            np.asarray(diff_ratios),\n",
    "            np.asarray(diff_indexs),\n",
    "            np.asarray(diff_scores),\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "\n",
    "        if len(partial_scores) % 10 == (samples-1)%10:\n",
    "            #print('Test')\n",
    "            print(\" radius = {}: Done with {} iterations. Time to match {:.3f} seconds.\".format(\n",
    "                radius,\n",
    "                len(partial_scores),\n",
    "                time.time()-t0)\n",
    "                 )\n",
    "            t0 = time.time()\n",
    "        \n",
    "            current_errors = NN_matcher(partial_scores)\n",
    "            print(\"   Error Rate:\",np.sum(current_errors[:,1]/len(partial_scores)))\n",
    "\n",
    "    partial_errors = NN_matcher(partial_scores)\n",
    "    print(radius,\"Error Rate:\",np.sum(partial_errors[:,1]/len(partial_scores)))\n",
    "                                                                                \n",
    "    with open('testing_results/partials/radius_{}_RAW_scores.pickle'.format(radius), 'wb') as f:\n",
    "        pickle.dump(partial_scores,f)\n",
    "                                              \n",
    "    with open('testing_results/partials/radius_{}_RAW_errors.pickle'.format(radius), 'wb') as f:\n",
    "        pickle.dump(partial_errors,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Testing our partial samples: RANSAC spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/jaybie/spatial-privacy/info3d.py:808: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(np.dot(testPlane[1],point[3:])/(LA.norm(testPlane[1])*LA.norm(point[3:]))) > max(0,(1-20*threshold)):\n",
      "/srv/jaybie/spatial-privacy/info3d.py:804: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs((np.dot(testPlane[1],point[:3])+d)*1.0/LA.norm(testPlane[1],ord = 2)) < threshold:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " radius = 0.5: Done with 9 iterations. Time to match 49.255 seconds.\n",
      "   Error Rate: 1.0\n",
      " radius = 0.5: Done with 19 iterations. Time to match 54.663 seconds.\n",
      "   Error Rate: 0.9999999999999998\n",
      " radius = 0.5: Done with 29 iterations. Time to match 53.633 seconds.\n",
      "   Error Rate: 0.9310344827586206\n",
      " radius = 0.5: Done with 39 iterations. Time to match 61.570 seconds.\n",
      "   Error Rate: 0.8974358974358975\n",
      " radius = 0.5: Done with 49 iterations. Time to match 51.490 seconds.\n",
      "   Error Rate: 0.857142857142857\n",
      "0.5 Error Rate: 0.8600000000000001\n",
      " radius = 1.0: Done with 9 iterations. Time to match 104.374 seconds.\n",
      "   Error Rate: 0.5555555555555556\n",
      " radius = 1.0: Done with 19 iterations. Time to match 116.070 seconds.\n",
      "   Error Rate: 0.6842105263157894\n",
      " radius = 1.0: Done with 29 iterations. Time to match 122.215 seconds.\n",
      "   Error Rate: 0.6206896551724137\n",
      " radius = 1.0: Done with 39 iterations. Time to match 125.586 seconds.\n",
      "   Error Rate: 0.5641025641025641\n",
      " radius = 1.0: Done with 49 iterations. Time to match 134.969 seconds.\n",
      "   Error Rate: 0.5918367346938775\n",
      "1.0 Error Rate: 0.5800000000000001\n",
      " radius = 1.5: Done with 9 iterations. Time to match 113.773 seconds.\n",
      "   Error Rate: 0.7777777777777777\n",
      " radius = 1.5: Done with 19 iterations. Time to match 122.464 seconds.\n",
      "   Error Rate: 0.6842105263157894\n",
      " radius = 1.5: Done with 29 iterations. Time to match 131.561 seconds.\n",
      "   Error Rate: 0.586206896551724\n",
      " radius = 1.5: Done with 39 iterations. Time to match 124.008 seconds.\n",
      "   Error Rate: 0.6153846153846154\n",
      " radius = 1.5: Done with 49 iterations. Time to match 135.905 seconds.\n",
      "   Error Rate: 0.5714285714285714\n",
      "1.5 Error Rate: 0.56\n"
     ]
    }
   ],
   "source": [
    "for radius in radius_range:\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    with open('testing_samples/{}_partial_point_cloud.pickle'.format(radius), 'rb') as f:\n",
    "        partial_point_collection = pickle.load(f)\n",
    "        samples = len(partial_point_collection)\n",
    "        \n",
    "    partial_scores = []\n",
    "    partial_properties = []\n",
    "    \n",
    "    for obj_meta, partial_pointcloud, partial_triangles in partial_point_collection:\n",
    "        \n",
    "        # ROTATION\n",
    "        random_theta =  (2*np.pi)*np.random.random()# from [0, 2pi)\n",
    "        random_axis = np.random.choice(np.arange(0,3))\n",
    "        rotated_pointCloud = rotatePointCloud(partial_pointcloud, random_theta, random_axis)\n",
    "\n",
    "        # TRANSLATION\n",
    "        t_pointCloud = np.asarray(rotated_pointCloud)\n",
    "        random_tx_axis = np.random.choice(np.arange(0,3))\n",
    "        random_translation = np.random.random()\n",
    "        t_pointCloud[:,random_tx_axis] = t_pointCloud[:,random_tx_axis] + random_translation\n",
    "        t_triangles = np.asarray(partial_triangles)#-vertices_length\n",
    "\n",
    "        #if object_name % 13 == 0:\n",
    "        #    print('{}: Processing iteration {} of object {}.'.format(radius,iteration,object_name))\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # GETTING GENERALIZATION\n",
    "        gen_planes = getRansacPlanes(\n",
    "            t_pointCloud\n",
    "        )\n",
    "\n",
    "        p_pointcloud, p_triangles = getGeneralizedPointCloud(\n",
    "            planes=gen_planes, \n",
    "        )\n",
    "\n",
    "        try:\n",
    "            p_descriptors, p_keypoints, p_d_c = getSpinImageDescriptors(\n",
    "                p_pointcloud,\n",
    "                down_resolution = 5,\n",
    "                cylindrical_quantization = [4,5]\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            print(\"Error getting descriptors of\",obj_meta)\n",
    "            print(\"Error Message:\",ex)\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # Resetting the diff_Ratio matrix\n",
    "        diff_scores = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "        diff_ratios = np.ones((p_descriptors.shape[0],len(descriptors)))\n",
    "        diff_indexs = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "\n",
    "        #print(diff_ratios.shape)\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        for i_r, ref_descriptor in enumerate(descriptors):\n",
    "\n",
    "            #o_, r_descriptors, r_keypoints, r_d_c\n",
    "            r_descriptors = ref_descriptor[1]\n",
    "            r_keypoints = ref_descriptor[2]\n",
    "\n",
    "            matching_range = np.arange(r_descriptors.shape[1])\n",
    "\n",
    "            try:    \n",
    "                f_nearestneighbor, diff = getMatches(p_descriptors,r_descriptors,2,range_to_match=matching_range)\n",
    "                diff = diff/np.amax(diff) # max-normalization of differences\n",
    "                diff_ratio = diff[:,0]/diff[:,1]\n",
    "                diff_ratios[:,i_r] = diff_ratio\n",
    "                diff_scores[:,i_r] = diff\n",
    "                diff_indexs[:,i_r] = f_nearestneighbor\n",
    "                \n",
    "                # Taking note of the matched keypoints\n",
    "                local_keypoint_matches.append([\n",
    "                    obj_meta,\n",
    "                    p_keypoints,\n",
    "                    r_keypoints[f_nearestneighbor[:,0]]\n",
    "                ])\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(rotation,\"Error Matching:\",ex)\n",
    "\n",
    "        # Accumulating the diff_ratio matrix for every partial (rotated) object\n",
    "        partial_scores.append([\n",
    "            obj_meta,\n",
    "            np.asarray(diff_ratios),\n",
    "            np.asarray(diff_indexs),\n",
    "            np.asarray(diff_scores),\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "\n",
    "        if len(partial_scores) % 10 == (samples-1)%10:\n",
    "            #print('Test')\n",
    "            print(\" radius = {}: Done with {} iterations. Time to match {:.3f} seconds.\".format(\n",
    "                radius,\n",
    "                len(partial_scores),\n",
    "                time.time()-t0)\n",
    "                 )\n",
    "            t0 = time.time()\n",
    "        \n",
    "            current_errors = NN_matcher(partial_scores)\n",
    "            print(\"   Error Rate:\",np.sum(current_errors[:,1]/len(partial_scores)))\n",
    "\n",
    "    partial_errors = NN_matcher(partial_scores)\n",
    "    print(radius,\"Error Rate:\",np.sum(partial_errors[:,1]/len(partial_scores)))\n",
    "                                                                                \n",
    "    with open('testing_results/partials/radius_{}_RANSAC_scores.pickle'.format(radius), 'wb') as f:\n",
    "        pickle.dump(partial_scores,f)\n",
    "                                              \n",
    "    with open('testing_results/partials/radius_{}_RANSAC_errors.pickle'.format(radius), 'wb') as f:\n",
    "        pickle.dump(partial_errors,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Results of partial spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f8ef48f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(9, 3))\n",
    "\n",
    "RawNN = []\n",
    "RansacGeneralizedNN = []\n",
    "\n",
    "RawNN_intra_errors = []\n",
    "RansacGeneralizedNN_intra_errors = []\n",
    "\n",
    "for radius in radius_range:\n",
    "    \n",
    "    try:\n",
    "        with open('testing_results/partials/radius_{}_RAW_errors.pickle'.format(radius), 'rb') as f:\n",
    "            partial_errors = pickle.load(f)\n",
    "\n",
    "        RawNN.append([\n",
    "            radius,\n",
    "            np.mean(partial_errors[:,1]),\n",
    "            np.std(partial_errors[:,1]),\n",
    "        ])\n",
    "        \n",
    "        correct_interspace_labels_idxs = np.where(partial_errors[:,1]==0)[0]\n",
    "\n",
    "        intraspace_errors  = partial_errors[correct_interspace_labels_idxs,2]\n",
    "\n",
    "        RawNN_intra_errors.append([\n",
    "            radius,\n",
    "            np.nanmean(intraspace_errors),\n",
    "            np.nanstd(intraspace_errors)\n",
    "        ])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        with open('testing_results/partials/radius_{}_RANSAC_errors.pickle'.format(radius), 'rb') as f:\n",
    "            partial_errors = pickle.load(f)\n",
    "\n",
    "        RansacGeneralizedNN.append([\n",
    "            radius,\n",
    "            np.nanmean(partial_errors[:,1]),\n",
    "            np.nanstd(partial_errors[:,1]),\n",
    "        ])\n",
    "\n",
    "        correct_interspace_labels_idxs = np.where(partial_errors[:,1]==0)[0]\n",
    "\n",
    "        intraspace_errors  = partial_errors[correct_interspace_labels_idxs,2]\n",
    "\n",
    "        RansacGeneralizedNN_intra_errors.append([\n",
    "            radius,\n",
    "            np.nanmean(intraspace_errors),\n",
    "            np.nanstd(intraspace_errors)\n",
    "        ])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "RansacGeneralizedNN = np.asarray(RansacGeneralizedNN)\n",
    "RawNN = np.asarray(RawNN)\n",
    "\n",
    "RawNN_intra_errors = np.asarray(RawNN_intra_errors)\n",
    "RansacGeneralizedNN_intra_errors = np.asarray(RansacGeneralizedNN_intra_errors)\n",
    "\n",
    "ax1 = fig.add_subplot(121) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(radius_range[0]-0.25,radius_range[-1]+0.25)\n",
    "markersize = 8\n",
    "\n",
    "ax1.set_ylabel(\"INTER-space Privacy\")\n",
    "ax1.set_xlabel(\"Partial Radius\")\n",
    "#ax1.set_yticklabels(fontsize = 16)\n",
    "#ax1.set_xticklabels(fontsize = 16)\n",
    "\n",
    "ax1.plot(\n",
    "    RawNN[:,0],RawNN[:,1],\n",
    "    \"-o\",\n",
    "    linewidth = 2,\n",
    "    mew = 2,markersize = markersize,\n",
    "    label = \"Raw\"\n",
    ")\n",
    "ax1.plot(\n",
    "    RansacGeneralizedNN[:,0],RansacGeneralizedNN[:,1],\n",
    "    \"-s\",\n",
    "    linewidth = 2,\n",
    "    mew = 2,markersize = markersize,\n",
    "    label = \"RANSAC\"\n",
    ")\n",
    "\n",
    "ax1.legend(loc = \"lower left\")\n",
    "\n",
    "ax2 = fig.add_subplot(122) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,10.25)\n",
    "ax2.set_xlim(radius_range[0]-0.25,radius_range[-1]+0.25)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy\")\n",
    "ax2.set_xlabel(\"Partial Radius\")\n",
    "#ax2.set_yticklabels(fontsize = 16)\n",
    "#ax2.set_xticklabels(fontsize = 16)\n",
    "\n",
    "plt.minorticks_on()\n",
    "\n",
    "ax2.plot(\n",
    "    RawNN_intra_errors[:,0],\n",
    "    RawNN_intra_errors[:,1], \n",
    "    linewidth = 2,\n",
    "    marker = 'o',fillstyle = 'none',\n",
    "    mew = 2,markersize = markersize,\n",
    "    label = \"Raw\"\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    RansacGeneralizedNN_intra_errors[:,0],\n",
    "    RansacGeneralizedNN_intra_errors[:,1], \n",
    "    linewidth = 2, \n",
    "    marker = 's',fillstyle = 'none',\n",
    "    mew = 2,markersize = markersize,\n",
    "    label = \"RANSAC\"\n",
    ")\n",
    "\n",
    "ax2.legend(loc = \"lower left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Testing with successively released partial spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "# We used a radius range of 0.25 to 5.0 in increments of 0.25.\n",
    "radius_range = radius_range[:2]\n",
    "\n",
    "# For our work, we orignally used 50 samples with further 100 successive releases for our investigation.\n",
    "# Below are lower parameters, change as desired.\n",
    "#samples = 50\n",
    "#releases = 50\n",
    "\n",
    "# For demonstration purposes, we skip testing some successive samples but we still accumulate them.\n",
    "skip = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Testing the successive case: RAW and RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/jaybie/spatial-privacy/info3d.py:889: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(np.dot(firstPlane[1],point[3:])/(LA.norm(firstPlane[1])*LA.norm(point[3:]))) > (1-20*threshold):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  radius = 0.5: Done with 2 releases (4) (0 samples). Time to match 48.022 seconds. ((3187, 6))\n",
      "   Error Rate: 0.0\n",
      "  radius = 0.5 [G]: Done with 2 releases (4) (0 samples). Time to match 3.227 seconds. ((624, 6))\n",
      "   G_Error Rate: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/jaybie/spatial-privacy/info3d.py:1011: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(np.dot(testPlane[1],point[3:])/(LA.norm(testPlane[1])*LA.norm(point[3:]))) > max(0,(1-20*threshold)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  radius = 0.5: Done with 4 releases (10) (0 samples). Time to match 55.975 seconds. ((3276, 6))\n",
      "   Error Rate: 0.0\n",
      "  radius = 0.5 [G]: Done with 4 releases (10) (0 samples). Time to match 4.909 seconds. ((993, 6))\n",
      "   G_Error Rate: 0.75\n",
      "  radius = 0.5: Done with 6 releases (16) (0 samples). Time to match 55.632 seconds. ((3279, 6))\n",
      "   Error Rate: 0.0\n",
      "  radius = 0.5 [G]: Done with 6 releases (16) (0 samples). Time to match 6.254 seconds. ((1549, 6))\n",
      "   G_Error Rate: 0.8333333333333333\n",
      "  radius = 0.5: Done with 8 releases (22) (0 samples). Time to match 59.814 seconds. ((3912, 6))\n",
      "   Error Rate: 0.0\n",
      "  radius = 0.5 [G]: Done with 8 releases (22) (0 samples). Time to match 10.459 seconds. ((2623, 6))\n",
      "   G_Error Rate: 0.75\n",
      "  radius = 0.5: Done with 10 releases (28) (0 samples). Time to match 67.911 seconds. ((4009, 6))\n",
      "   Error Rate: 0.0\n",
      "  radius = 0.5 [G]: Done with 10 releases (28) (0 samples). Time to match 11.746 seconds. ((3247, 6))\n",
      "   G_Error Rate: 0.7000000000000001\n",
      "  radius = 0.5: Done with 2 releases (4) (1 samples). Time to match 21.916 seconds. ((1087, 6))\n",
      "   Error Rate: 0.5\n",
      "  radius = 0.5 [G]: Done with 2 releases (4) (1 samples). Time to match 3.976 seconds. ((934, 6))\n",
      "   G_Error Rate: 1.0\n",
      "  radius = 0.5: Done with 4 releases (10) (1 samples). Time to match 40.636 seconds. ((2445, 6))\n",
      "   Error Rate: 0.75\n",
      "  radius = 0.5 [G]: Done with 4 releases (10) (1 samples). Time to match 11.162 seconds. ((2569, 6))\n",
      "   G_Error Rate: 0.75\n",
      "  radius = 0.5: Done with 6 releases (16) (1 samples). Time to match 74.156 seconds. ((4240, 6))\n",
      "   Error Rate: 0.6666666666666666\n",
      "  radius = 0.5 [G]: Done with 6 releases (16) (1 samples). Time to match 22.344 seconds. ((5982, 6))\n",
      "   G_Error Rate: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "for radius in radius_range:\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    try:\n",
    "        with open('testing_samples/{}_successive_point_cloud.pickle'.format(radius), 'rb') as f:\n",
    "            successive_point_collection = pickle.load(f)\n",
    "            samples = len(successive_point_collection)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    successive_scores = []\n",
    "    successive_errors = []\n",
    "    \n",
    "    g_successive_scores = []\n",
    "    g_successive_errors = []\n",
    "\n",
    "    for obj_, growing_point_collection in successive_point_collection:\n",
    "        \n",
    "        iteration_scores = []\n",
    "        \n",
    "        g_iteration_scores = []\n",
    "        \n",
    "        # ROTATION param\n",
    "        random_theta =  (2*np.pi)*np.random.random()# from [0, 2pi)\n",
    "        random_axis = np.random.choice(np.arange(0,3))\n",
    "        \n",
    "        # TRANSLATION param\n",
    "        random_tx_axis = np.random.choice(np.arange(0,3))\n",
    "        random_translation = np.random.random()\n",
    "        \n",
    "        growing_point_cloud = []\n",
    "        growing_p_point_cloud = []\n",
    "        growing_p_triangles = []\n",
    "        \n",
    "        releases = len(growing_point_collection)\n",
    "        release_count = 0\n",
    "    \n",
    "        for obj_meta, partial_pointcloud, partial_triangles in growing_point_collection:\n",
    "            #i_obj, released_growing_point_collection in enumerate(growing_point_collection):\n",
    "\n",
    "            rotated_pointCloud = rotatePointCloud(partial_pointcloud, random_theta, random_axis)\n",
    "\n",
    "            # TRANSLATION\n",
    "            t_pointCloud = np.asarray(rotated_pointCloud)\n",
    "            t_pointCloud[:,random_tx_axis] = t_pointCloud[:,random_tx_axis] + random_translation\n",
    "            t_triangles = np.asarray(partial_triangles)#-vertices_length\n",
    "            \n",
    "            #Regular Accumulation\n",
    "            if len(growing_point_cloud) == 0:\n",
    "                growing_point_cloud = t_pointCloud\n",
    "\n",
    "            else:\n",
    "                growing_point_cloud = np.concatenate(\n",
    "                    (growing_point_cloud,t_pointCloud),\n",
    "                    axis=0\n",
    "                )\n",
    "                \n",
    "            #RANSAC generalizations\n",
    "            if len(growing_p_point_cloud) == 0:\n",
    "                gen_planes = getLOCALIZEDRansacPlanes(\n",
    "                    pointCloud = t_pointCloud,\n",
    "                    original_vertex = obj_meta[-1]\n",
    "                )\n",
    "            else:\n",
    "                gen_planes = updatePlanesWithSubsumption(\n",
    "                    new_pointCloud=t_pointCloud,\n",
    "                    existing_pointCloud=growing_p_point_cloud,\n",
    "                    planes_to_find = max(min(release_count,50),30),\n",
    "                    #verbose=True\n",
    "                )\n",
    "            \n",
    "            if len(gen_planes) == 0:\n",
    "                print(\"No gen planes after release\",release_count,growing_point_cloud.shape)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                updated_point_cloud, updated_triangles = getGeneralizedPointCloud(\n",
    "                    planes = gen_planes,\n",
    "                    triangle_area_threshold = 0.2,#2.0*np.amax(getTriangleAreas(partial_pointCloud, partial_triangles))\n",
    "                    #verbose = True\n",
    "                )\n",
    "                growing_p_point_cloud = updated_point_cloud\n",
    "                growing_p_triangles = updated_triangles\n",
    "                \n",
    "                #print(\" Successful:\",release_count,len(growing_p_point_cloud), len(growing_p_triangles),partial_pointCloud.shape)\n",
    "            except Exception as ex:\n",
    "                print(\"Error getting updated point cloud in release\",release_count+1)\n",
    "                print(\" \",growing_p_point_cloud.shape, growing_p_triangles.shape,partial_pointCloud.shape)\n",
    "                #print(ex)\n",
    "                continue\n",
    "                \n",
    "            if len(growing_p_point_cloud) == 0:\n",
    "                continue\n",
    "                \n",
    "            release_count += 1\n",
    "            \n",
    "            if release_count % skip != 1: # skip \n",
    "                continue\n",
    "                \n",
    "            #Regular Processing\n",
    "            growing_point_cloud = np.unique(growing_point_cloud,axis=0)\n",
    "            \n",
    "            try:\n",
    "                p_descriptors, p_keypoints, p_d_c = getSpinImageDescriptors(\n",
    "                    growing_point_cloud,\n",
    "                    down_resolution = 5,\n",
    "                    cylindrical_quantization = [4,5]\n",
    "                )\n",
    "            except:\n",
    "                p_descriptors = []\n",
    "                p_keypoints = []\n",
    "\n",
    "            # Resetting the diff_Ratio matrix\n",
    "            diff_scores = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "            diff_ratios = np.ones((p_descriptors.shape[0],len(descriptors)))\n",
    "            diff_indexs = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "\n",
    "            local_keypoint_matches = []\n",
    "\n",
    "            for i_r, ref_descriptor in enumerate(descriptors):\n",
    "\n",
    "                r_descriptors = ref_descriptor[1]\n",
    "                r_keypoints = ref_descriptor[2]\n",
    "\n",
    "                matching_range = np.arange(r_descriptors.shape[1])\n",
    "\n",
    "                try:    \n",
    "                    f_nearestneighbor, diff = getMatches(p_descriptors,r_descriptors,2,range_to_match=matching_range)\n",
    "                    diff = diff/np.amax(diff) # max-normalization of differences\n",
    "                    diff_ratio = diff[:,0]/diff[:,1]\n",
    "                    diff_ratios[:,i_r] = diff_ratio\n",
    "                    diff_scores[:,i_r] = diff\n",
    "                    diff_indexs[:,i_r] = f_nearestneighbor\n",
    "\n",
    "                    # Taking note of the matched keypoints\n",
    "                    local_keypoint_matches.append([\n",
    "                        obj_meta,\n",
    "                        p_keypoints,\n",
    "                        r_keypoints[f_nearestneighbor[:,0]]\n",
    "                    ])\n",
    "\n",
    "                except Exception as ex:\n",
    "                    print(rotation,\"Error Matching:\",ex)\n",
    "\n",
    "            # Accumulating the diff_ratio matrix for every partial (rotated) object\n",
    "            iteration_scores.append([\n",
    "                obj_meta,\n",
    "                diff_ratios,\n",
    "                diff_indexs,\n",
    "                diff_scores,\n",
    "                local_keypoint_matches\n",
    "            ])\n",
    "\n",
    "            if release_count % 2 == 0:\n",
    "                #print('Test')\n",
    "                print(\"  radius = {}: Done with {} releases ({}) ({} samples). Time to match {:.3f} seconds. ({})\".format(\n",
    "                    radius,\n",
    "                    len(iteration_scores),\n",
    "                    release_count,\n",
    "                    len(successive_scores),\n",
    "                    time.time()-t0,\n",
    "                    growing_point_cloud.shape\n",
    "                )\n",
    "                     )\n",
    "                t0 = time.time()\n",
    "\n",
    "                current_errors = NN_matcher(iteration_scores)\n",
    "                print(\"   Error Rate:\",np.sum(current_errors[:,1]/len(iteration_scores)))\n",
    "            \n",
    "            #RANSAC Processing         \n",
    "            try:\n",
    "                p_descriptors, p_keypoints, p_d_c = getSpinImageDescriptors(\n",
    "                    growing_p_point_cloud,\n",
    "                    down_resolution = 5,\n",
    "                    cylindrical_quantization = [4,5]\n",
    "                )\n",
    "            except:\n",
    "                p_descriptors = []\n",
    "                p_keypoints = []\n",
    "                \n",
    "                print(\"Error getting descriptors at release\",release_count,\"; using next release as this release.\")\n",
    "                \n",
    "                #release_count -= 1\n",
    "\n",
    "                continue\n",
    "\n",
    "            # Resetting the diff_Ratio matrix\n",
    "            diff_scores = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "            diff_ratios = np.ones((p_descriptors.shape[0],len(descriptors)))\n",
    "            diff_indexs = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "\n",
    "            local_keypoint_matches = []\n",
    "\n",
    "            for i_r, ref_descriptor in enumerate(descriptors):\n",
    "\n",
    "                #o_, r_descriptors, r_keypoints, r_d_c\n",
    "                r_descriptors = ref_descriptor[1]\n",
    "                r_keypoints = ref_descriptor[2]\n",
    "\n",
    "                matching_range = np.arange(r_descriptors.shape[1])\n",
    "\n",
    "                try:    \n",
    "                    f_nearestneighbor, diff = getMatches(p_descriptors,r_descriptors,2,range_to_match=matching_range)\n",
    "                    diff = diff/np.amax(diff) # max-normalization of differences\n",
    "                    diff_ratio = diff[:,0]/diff[:,1]\n",
    "                    diff_ratios[:,i_r] = diff_ratio\n",
    "                    diff_scores[:,i_r] = diff\n",
    "                    diff_indexs[:,i_r] = f_nearestneighbor\n",
    "\n",
    "                    # Taking note of the matched keypoints\n",
    "                    local_keypoint_matches.append([\n",
    "                        obj_meta,\n",
    "                        p_keypoints,\n",
    "                        r_keypoints[f_nearestneighbor[:,0]]\n",
    "                    ])\n",
    "\n",
    "                except Exception as ex:\n",
    "                    print(rotation,\"Error Matching:\",ex)\n",
    "\n",
    "            # Accumulating the diff_ratio matrix for every partial (rotated) object\n",
    "            g_iteration_scores.append([\n",
    "                obj_meta,\n",
    "                diff_ratios,\n",
    "                diff_indexs,\n",
    "                diff_scores,\n",
    "                local_keypoint_matches\n",
    "            ])\n",
    "\n",
    "            if release_count % 2 == 0:\n",
    "                #print('Test')\n",
    "                print(\"  radius = {} [G]: Done with {} releases ({}) ({} samples). Time to match {:.3f} seconds. ({})\".format(\n",
    "                    radius,\n",
    "                    len(g_iteration_scores),\n",
    "                    release_count,\n",
    "                    len(g_successive_scores),\n",
    "                    time.time()-t0,\n",
    "                    growing_p_point_cloud.shape\n",
    "                )\n",
    "                     )\n",
    "                t0 = time.time()\n",
    "\n",
    "                current_errors = NN_matcher(g_iteration_scores)\n",
    "                print(\"   G_Error Rate:\",np.sum(current_errors[:,1]/len(g_iteration_scores)))\n",
    "\n",
    "        iteration_errors = NN_matcher(iteration_scores)\n",
    "\n",
    "        g_iteration_errors = NN_matcher(g_iteration_scores)\n",
    "\n",
    "        if len(successive_scores) % 5 == (samples-1)%5 :\n",
    "            try:\n",
    "                print(radius,len(successive_scores),\"Error Rate:\",np.sum(iteration_errors[:,1]/len(iteration_scores)))\n",
    "                print(radius,len(g_successive_scores),\"G_Error Rate:\",np.sum(g_iteration_errors[:,1]/len(g_iteration_scores)))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        successive_scores.append([\n",
    "            obj_,\n",
    "            iteration_scores\n",
    "        ])\n",
    "        \n",
    "        successive_errors.append([\n",
    "            obj_,\n",
    "            iteration_errors\n",
    "        ])\n",
    "        \n",
    "        g_successive_scores.append([\n",
    "            obj_,\n",
    "            g_iteration_scores\n",
    "        ])\n",
    "        \n",
    "        g_successive_errors.append([\n",
    "            obj_,\n",
    "            g_iteration_errors\n",
    "        ])\n",
    "    \n",
    "        with open('testing_results/successive/radius_{}_RAW_successive_scores.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(successive_scores,f)\n",
    "\n",
    "        with open('testing_results/successive/radius_{}_RAW_successive_errors.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(successive_errors,f)\n",
    "\n",
    "        with open('testing_results/successive/radius_{}_RANSAC_successive_scores.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(g_successive_scores,f)\n",
    "\n",
    "        with open('testing_results/successive/radius_{}_RANSAC_successive_errors.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(g_successive_errors,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Results of the successive case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_RawNN_errors = []\n",
    "succ_RawNN_partial_errors = []\n",
    "\n",
    "succ_RansacGeneralizedNN_errors = []\n",
    "succ_RansacGeneralizedNN_partial_errors = []\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for radius in radius_range:\n",
    "    \n",
    "    succ_RawNN_per_iteration_errors = []\n",
    "    succ_RansacGeneralizedNN_per_iteration_errors = []\n",
    "\n",
    "    try:\n",
    "                \n",
    "        with open('testing_results/successive/radius_{}_RAW_successive_scores.pickle'.format(radius), 'rb') as f:\n",
    "            successive_scores = pickle.load(f)\n",
    "\n",
    "        with open('testing_results/successive/radius_{}_RAW_successive_errors.pickle'.format(radius), 'rb') as f:\n",
    "            successive_errors = pickle.load(f)\n",
    "        \n",
    "        for obj_, iteration_errors in successive_errors:    \n",
    "            #print(\"  RAW\",radius,iteration_errors.shape)\n",
    "\n",
    "            if iteration_errors.shape[0] < int(releases/skip):\n",
    "                continue\n",
    "            else:\n",
    "                succ_RawNN_per_iteration_errors.append(iteration_errors[:int(releases/skip)])\n",
    "       \n",
    "        succ_RawNN_errors.append([\n",
    "            radius,\n",
    "            np.asarray(succ_RawNN_per_iteration_errors)\n",
    "        ])\n",
    "        \n",
    "        print(np.asarray(succ_RawNN_per_iteration_errors).shape)\n",
    "\n",
    "    except:# Exception as ex:\n",
    "        #print(radius,\": successive RawNN\\n  \", ex)\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "                \n",
    "        with open('testing_results/successive/radius_{}_RANSAC_successive_scores.pickle'.format(radius), 'rb') as f:\n",
    "            successive_scores = pickle.load(f)\n",
    "\n",
    "        with open('testing_results/successive/radius_{}_RANSAC_successive_errors.pickle'.format(radius), 'rb') as f:\n",
    "            successive_errors = pickle.load(f)\n",
    "        \n",
    "        for obj_, iteration_scores in successive_scores:#[:-1]:    \n",
    "            #print(\"  RANSAC\",radius,iteration_errors.shape)\n",
    "            iteration_errors = NN_matcher(iteration_scores)\n",
    "\n",
    "            if iteration_errors.shape[0] < int(releases/skip):\n",
    "                continue\n",
    "            else:\n",
    "                succ_RansacGeneralizedNN_per_iteration_errors.append(iteration_errors[:int(releases/skip)])\n",
    "       \n",
    "        succ_RansacGeneralizedNN_errors.append([\n",
    "            radius,\n",
    "            np.asarray(succ_RansacGeneralizedNN_per_iteration_errors)\n",
    "        ])\n",
    "        \n",
    "        print(np.asarray(succ_RansacGeneralizedNN_errors).shape)\n",
    "\n",
    "    except:# Exception as ex:\n",
    "        #print(radius,\": successive RansacNN\\n  \", ex)\n",
    "        pass\n",
    "    \n",
    "    print(\"Done with radius = {:.2f} in {:.3f} seconds\".format(radius,time.time() - t0))\n",
    "    t0 = time.time()\n",
    "    \n",
    "for radius, per_iteration_errors in succ_RawNN_errors:\n",
    "\n",
    "    #print(per_iteration_errors.shape)\n",
    "\n",
    "    succ_RawNN_partial_errors_per_rel = []\n",
    "\n",
    "    for rel_i in np.arange(per_iteration_errors.shape[1]):\n",
    "\n",
    "        correct_interspace_labels_idxs = np.where(per_iteration_errors[:,rel_i,1]==0)[0]\n",
    "\n",
    "        intraspace_errors  = per_iteration_errors[correct_interspace_labels_idxs,rel_i,2]\n",
    "\n",
    "        succ_RawNN_partial_errors_per_rel.append([\n",
    "            rel_i,\n",
    "            np.mean(intraspace_errors),\n",
    "            np.std(intraspace_errors)\n",
    "        ])\n",
    "\n",
    "    succ_RawNN_partial_errors.append([\n",
    "        radius,\n",
    "        np.asarray(succ_RawNN_partial_errors_per_rel)\n",
    "    ])\n",
    "    \n",
    "for radius, per_iteration_errors in succ_RansacGeneralizedNN_errors:\n",
    "\n",
    "    #print(radius,per_iteration_errors.shape)\n",
    "\n",
    "    succ_RansacGeneralizedNN_errors_per_rel = []\n",
    "\n",
    "    for rel_i in np.arange(per_iteration_errors.shape[1]):\n",
    "\n",
    "        correct_interspace_labels_idxs = np.where(per_iteration_errors[:,rel_i,1]==0)[0]\n",
    "\n",
    "        intraspace_errors  = per_iteration_errors[correct_interspace_labels_idxs,rel_i,2]\n",
    "\n",
    "        succ_RansacGeneralizedNN_errors_per_rel.append([\n",
    "            rel_i,\n",
    "            np.mean(intraspace_errors),\n",
    "            np.std(intraspace_errors)\n",
    "        ])\n",
    "\n",
    "    succ_RansacGeneralizedNN_partial_errors.append([\n",
    "        radius,\n",
    "        np.asarray(succ_RansacGeneralizedNN_errors_per_rel)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(121) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(0,releases-skip)\n",
    "markersize = 8\n",
    "\n",
    "ax1.set_ylabel(\"INTER-space Privacy\")\n",
    "ax1.set_xlabel(\"Releases\")\n",
    "\n",
    "for radius, RawNN_per_iteration_errors in succ_RawNN_errors:\n",
    "    print(RawNN_per_iteration_errors.shape)\n",
    "    ax1.plot(\n",
    "        np.arange(1,releases-skip,skip),#[:RawNN_per_iteration_errors.shape[1]],\n",
    "        np.mean(RawNN_per_iteration_errors[:,:,1], axis = 0), \n",
    "        ':o',\n",
    "        label = \"r =\"+ str(radius) + \" Raw\"\n",
    "    )\n",
    "    \n",
    "for radius, RansacNN_per_iteration_errors in succ_RansacGeneralizedNN_errors:\n",
    "    print(RansacNN_per_iteration_errors.shape)\n",
    "    ax1.plot(\n",
    "        np.arange(1,releases-skip,skip),\n",
    "        np.mean(RansacNN_per_iteration_errors[:,:,1], axis = 0),\n",
    "        '-s',\n",
    "        label = \"r =\"+ str(radius) + \" RANSAC\"\n",
    "    )\n",
    "\n",
    "ax1.legend(loc = \"best\", ncol = 2)\n",
    "\n",
    "ax2 = fig.add_subplot(122) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,12.25)\n",
    "ax2.set_xlim(0,releases-skip)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy\")\n",
    "ax2.set_xlabel(\"Partial Radius\")\n",
    "#ax2.set_yticklabels(fontsize = 16)\n",
    "#ax2.set_xticklabels(fontsize = 16)\n",
    "\n",
    "#plt.minorticks_on()\n",
    "\n",
    "for radius, errors_per_rel in succ_RansacGeneralizedNN_partial_errors:\n",
    "    ax2.plot(\n",
    "        np.arange(1,releases-skip,skip),\n",
    "        errors_per_rel[:,1], \n",
    "        #errors_per_rel[:,2],\n",
    "        '-s',\n",
    "        linewidth = 2, #capsize = 4.0, \n",
    "        #marker = markers[0],\n",
    "        #fillstyle = 'none',\n",
    "        mew = 2, markersize = markersize,\n",
    "        label = \"r =\"+ str(radius)+\", RANSAC\"\n",
    "    )\n",
    "\n",
    "ax2.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.1 Testing with conservative plane releasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters:\n",
    "\n",
    "Also, we use the same successive samples from successive releasing for direct comparability of results.\n",
    "\"\"\"\n",
    "# We used a radius range of 0.25 to 5.0 in increments of 0.25.\n",
    "radius_range = radius_range\n",
    "\n",
    "# For our work, we orignally used 50 samples with further 100 successive releases for our investigation.\n",
    "# Below are lower parameters, change as desired.\n",
    "samples = 50\n",
    "releases = 50\n",
    "\n",
    "planes = np.arange(1,30,3)\n",
    "\n",
    "# For demonstration purposes, we skip testing some successive samples but we still accumulate them.\n",
    "skip = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for radius in radius_range[:2]:\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    try:\n",
    "        with open('testing_samples/{}_successive_point_cloud.pickle'.format(radius), 'rb') as f:\n",
    "            successive_point_collection = pickle.load(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    conservative_scores = []\n",
    "    conservative_errors = []\n",
    "    \n",
    "    for obj_, growing_point_collection in successive_point_collection:\n",
    "        \n",
    "        # ROTATION param\n",
    "        random_theta =  (2*np.pi)*np.random.random()# from [0, 2pi)\n",
    "        random_axis = np.random.choice(np.arange(0,3))\n",
    "        \n",
    "        # TRANSLATION param\n",
    "        random_tx_axis = np.random.choice(np.arange(0,3))\n",
    "        random_translation = np.random.random()\n",
    "        \n",
    "        per_plane_scores = []\n",
    "        per_plane_errors = []\n",
    "        \n",
    "        latest_plane = 0\n",
    "        \n",
    "        for plane_number in planes:\n",
    "            \n",
    "            print(radius,\" {} planes, ({} Done)\".format(plane_number,len(per_plane_successive_scores)))\n",
    "        \n",
    "            g_iteration_scores = []\n",
    "\n",
    "            growing_point_cloud = []\n",
    "            growing_p_point_cloud = []\n",
    "            growing_p_triangles = []\n",
    "\n",
    "            release_count = 0\n",
    "            \n",
    "            for obj_meta, partial_pointcloud, partial_triangles in growing_point_collection:\n",
    "                #i_obj, released_growing_point_collection in enumerate(growing_point_collection):\n",
    "\n",
    "                # ROTATION\n",
    "                rotated_pointCloud = rotatePointCloud(partial_pointcloud, random_theta, random_axis)\n",
    "\n",
    "                # TRANSLATION\n",
    "                t_pointCloud = np.asarray(rotated_pointCloud)\n",
    "                t_pointCloud[:,random_tx_axis] = t_pointCloud[:,random_tx_axis] + random_translation\n",
    "                t_triangles = np.asarray(partial_triangles)#-vertices_length\n",
    "\n",
    "                #RANSAC generalizations\n",
    "                try:\n",
    "                    if len(growing_p_point_cloud) == 0:\n",
    "                        gen_planes = getLOCALIZEDRansacPlanes(\n",
    "                            pointCloud = t_pointCloud,#np.where(hPointConnectivity < 5)[0],axis = 0),\n",
    "                            original_vertex = obj_meta[-1],\n",
    "                            planes_to_find=plane_number\n",
    "                            #verbose=True\n",
    "                            #threshold = threshold # the point-plane distance threshold\n",
    "                        )\n",
    "                    else:\n",
    "                        gen_planes = updatePlanesWithSubsumption(\n",
    "                            new_pointCloud=t_pointCloud,\n",
    "                            existing_pointCloud=growing_p_point_cloud,\n",
    "                            planes_to_find = plane_number\n",
    "                            #verbose=True\n",
    "                        )\n",
    "                except:\n",
    "                    print(\"Error getting planes\",release_count,growing_point_cloud.shape)\n",
    "                    continue\n",
    "\n",
    "                if len(gen_planes) == 0:\n",
    "                    print(\"No gen planes after release\",release_count,growing_point_cloud.shape)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    updated_point_cloud, updated_triangles = getGeneralizedPointCloud(\n",
    "                        planes = gen_planes,\n",
    "                        triangle_area_threshold = 0.2,#2.0*np.amax(getTriangleAreas(partial_pointCloud, partial_triangles))\n",
    "                        #verbose = True\n",
    "                    )\n",
    "                    growing_p_point_cloud = updated_point_cloud\n",
    "                    growing_p_triangles = updated_triangles\n",
    "\n",
    "                    #print(\" Successful:\",release_count,len(growing_p_point_cloud), len(growing_p_triangles),partial_pointCloud.shape)\n",
    "                except Exception as ex:\n",
    "                    print(\"Error getting updated point cloud in release\",release_count+1)\n",
    "                    print(\" \",growing_p_point_cloud.shape, growing_p_triangles.shape,partial_pointCloud.shape)\n",
    "                    #print(ex)\n",
    "                    continue\n",
    "\n",
    "                if len(growing_p_point_cloud) == 0:\n",
    "                    continue\n",
    "\n",
    "                release_count += 1\n",
    "\n",
    "                if release_count % skip != 1: # skip \n",
    "                    continue\n",
    "\n",
    "                #RANSAC Processing         \n",
    "                try:\n",
    "                    p_descriptors, p_keypoints, p_d_c = getSpinImageDescriptors(\n",
    "                        growing_p_point_cloud,\n",
    "                        down_resolution = 5,\n",
    "                        cylindrical_quantization = [4,5]\n",
    "                    )\n",
    "                except:\n",
    "                    p_descriptors = []\n",
    "                    p_keypoints = []\n",
    "\n",
    "                    print(\"Error getting descriptors at release\",release_count,\"; using next release as this release.\")\n",
    "\n",
    "                    #release_count -= 1\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # Resetting the diff_Ratio matrix\n",
    "                diff_scores = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "                diff_ratios = np.ones((p_descriptors.shape[0],len(descriptors)))\n",
    "                diff_indexs = np.ones((p_descriptors.shape[0],len(descriptors),2))\n",
    "\n",
    "                local_keypoint_matches = []\n",
    "\n",
    "                for i_r, ref_descriptor in enumerate(descriptors):\n",
    "\n",
    "                    #o_, r_descriptors, r_keypoints, r_d_c\n",
    "                    r_descriptors = ref_descriptor[1]\n",
    "                    r_keypoints = ref_descriptor[2]\n",
    "\n",
    "                    matching_range = np.arange(r_descriptors.shape[1])\n",
    "\n",
    "                    try:    \n",
    "                        f_nearestneighbor, diff = getMatches(p_descriptors,r_descriptors,2,range_to_match=matching_range)\n",
    "                        diff = diff/np.amax(diff) # max-normalization of differences\n",
    "                        diff_ratio = diff[:,0]/diff[:,1]\n",
    "                        diff_ratios[:,i_r] = diff_ratio\n",
    "                        diff_scores[:,i_r] = diff\n",
    "                        diff_indexs[:,i_r] = f_nearestneighbor\n",
    "\n",
    "                        # Taking note of the matched keypoints\n",
    "                        local_keypoint_matches.append([\n",
    "                            obj_meta,\n",
    "                            p_keypoints,\n",
    "                            r_keypoints[f_nearestneighbor[:,0]]\n",
    "                        ])\n",
    "\n",
    "                    except Exception as ex:\n",
    "                        print(rotation,\"Error Matching:\",ex)\n",
    "\n",
    "                # Accumulating the diff_ratio matrix for every partial (rotated) object\n",
    "                g_iteration_scores.append([\n",
    "                    obj_meta,\n",
    "                    diff_ratios,\n",
    "                    diff_indexs,\n",
    "                    diff_scores,\n",
    "                    local_keypoint_matches\n",
    "                ])\n",
    "\n",
    "        # --- !\n",
    "                if release_count % 2 == 0:\n",
    "                    #print('Test')\n",
    "                    print(\"  radius = {} [G]: Done with {} releases ({}) ({} samples). Time to match {:.3f} seconds. ({})\".format(\n",
    "                        radius,\n",
    "                        len(g_iteration_scores),\n",
    "                        release_count,\n",
    "                        len(g_successive_scores),\n",
    "                        time.time()-t0,\n",
    "                        growing_p_point_cloud.shape\n",
    "                    )\n",
    "                         )\n",
    "                    t0 = time.time()\n",
    "\n",
    "                    current_errors = NN_matcher(g_iteration_scores)\n",
    "                    print(\"   ({} actual planes) G_Error Rate: {}\".format(\n",
    "                        len(gen_planes),\n",
    "                        np.sum(current_errors[:,1]/len(g_iteration_scores))\n",
    "                    ))\n",
    "\n",
    "                g_iteration_errors = NN_matcher(g_iteration_scores)\n",
    "            try:\n",
    "                print(radius,plane_number,len(g_successive_scores),\"G_Error Rate:\",np.sum(g_iteration_errors[:,1]/len(g_iteration_scores)))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            per_plane_scores.append([\n",
    "                plane_number,\n",
    "                g_iteration_scores\n",
    "            ])\n",
    "\n",
    "            per_plane_errors.append([\n",
    "                plane_number,\n",
    "                g_iteration_errors\n",
    "            ])\n",
    "\n",
    "        conservative_scores.append([\n",
    "            obj_,\n",
    "            per_plane_scores\n",
    "        ])\n",
    "\n",
    "        conservative_errors.append([\n",
    "            obj_,\n",
    "            per_plane_errors\n",
    "        ])\n",
    "        \n",
    "        if len(successive_scores) % 5 == (samples-1)%5 :\n",
    "            try:\n",
    "                print(\"Radius = {}, {} objects done\".format(radius,len(g_successive_scores)))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        with open('testing_results/conservative/radius_{}_RANSAC_conservative_scores.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(conservative_scores,f)\n",
    "\n",
    "        with open('testing_results/conservative/radius_{}_RANSAC_conservative_errors.pickle'.format(radius), 'wb') as f:\n",
    "            pickle.dump(conservative_errors,f)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Results with conservative plane releasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_RANSAC_error_results = []\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for radius in radius_range:\n",
    "    \n",
    "    succ_RansacGeneralizedNN_per_iteration_errors = []\n",
    "    \n",
    "    try:\n",
    "                \n",
    "        with open('testing_results/conservative/radius_{}_RANSAC_conservative_scores.pickle'.format(radius), 'rb') as f:\n",
    "            conservative_scores = pickle.load(f)\n",
    "\n",
    "        with open('testing_results/conservative/radius_{}_RANSAC_conservative_errors.pickle'.format(radius), 'rb') as f:\n",
    "            conservative_errors = pickle.load(f)\n",
    "        \n",
    "        for obj_, per_plane_scores in successive_scores:#[:-1]:  \n",
    "            \n",
    "            per_plane_errors = []\n",
    "            \n",
    "            skip = False\n",
    "            \n",
    "            for planes, iteration_scores in per_plane_scores:\n",
    "                #print(iteration_errors.shape)\n",
    "                \n",
    "                iteration_errors = NN_matcher(iteration_scores)\n",
    "                \n",
    "                #print(planes,iteration_errors.shape)\n",
    "\n",
    "                if iteration_errors.shape[0] >=18:\n",
    "                    per_plane_errors.append(iteration_errors[:18])\n",
    "                else:\n",
    "                    skip = True\n",
    "                    #print(\"RANSAC: skipped\",iteration_errors.shape)\n",
    "                    \n",
    "            if not skip:\n",
    "                succ_RansacGeneralizedNN_per_iteration_errors.append(per_plane_errors)\n",
    "       \n",
    "        conservative_RANSAC_error_results.append([\n",
    "            radius,\n",
    "            succ_RansacGeneralizedNN_per_iteration_errors\n",
    "        ])\n",
    "              \n",
    "    except Exception as ex:\n",
    "        print(radius,\": conservative RansacNN\\n  \", ex)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    print(\"Done with radius = {:.2f} in {:.3f} seconds\".format(radius,time.time() - t0))\n",
    "    t0 = time.time()\n",
    "    \n",
    "\"\"\"\n",
    "# Uncomment below if you want to overwrite the existing results.\n",
    "\"\"\"\n",
    "with open('testing_results/conservative/conservative_RANSAC_error_results.pickle', 'wb') as f:\n",
    "    pickle.dump(conservative_RANSAC_error_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Preparing the results of the case with *Conservative Releasing*.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "releases_range = np.arange(1,releases-skip,skip)\n",
    "\n",
    "X, Y = np.meshgrid(releases_range, planes)\n",
    "\n",
    "test_vp_cn_05 = np.asarray(conservative_RANSAC_error_results[0][1])\n",
    "mean_vp_cn_05 = np.mean(test_vp_cn_05[:,:,:,1],axis = 0)\n",
    "\n",
    "test_vp_cn_10 = np.asarray(conservative_RANSAC_error_results[1][1])\n",
    "mean_vp_cn_05 = np.mean(test_vp_cn_05[:,:,:,1],axis = 0)\n",
    "\n",
    "intra_vp_cn_10 = np.zeros(test_vp_cn_10.shape[1:])\n",
    "intra_vp_cn_05 = np.zeros(test_vp_cn_05.shape[1:])\n",
    "\n",
    "for plane_i, plane in enumerate(planes):\n",
    "        \n",
    "    for rel_i, rel in enumerate(releases_range):\n",
    "    \n",
    "        correct_interspace_labels_idxs_05 = np.where(test_vp_cn_05[:,plane_i,rel_i,1]==0)[0]\n",
    "        correct_interspace_labels_idxs_10 = np.where(test_vp_cn_10[:,plane_i,rel_i,1]==0)[0]\n",
    "\n",
    "        intraspace_errors_05  = test_vp_cn_05[correct_interspace_labels_idxs_05,plane_i,rel_i,2]\n",
    "        intraspace_errors_10  = test_vp_cn_10[correct_interspace_labels_idxs_10,plane_i,rel_i,2]\n",
    "        \n",
    "        intra_vp_cn_05[plane_i,rel_i] = np.asarray([\n",
    "            np.mean(intraspace_errors_05),\n",
    "            np.std(intraspace_errors_05),\n",
    "            0,\n",
    "            np.nan\n",
    "        ])\n",
    "        \n",
    "        intra_vp_cn_10[plane_i,rel_i] = np.asarray([\n",
    "            np.mean(intraspace_errors_10),\n",
    "            np.std(intraspace_errors_10),\n",
    "            0,\n",
    "            np.nan\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(\n",
    "    X, Y, \n",
    "    mean_vp_cn_05, \n",
    "    cmap=plt.cm.plasma,\n",
    ")\n",
    "surf.set_clim(0.0,1.0)\n",
    "\n",
    "ax.set_title(\"r = 0.5\", fontsize = 24)\n",
    "ax.set_xlabel(\"Releases\", labelpad=10, fontsize = 24)\n",
    "ax.set_xlim(0,100)\n",
    "ax.set_xticklabels(np.arange(0,101,20),fontsize = 16)\n",
    "ax.set_zlabel(\"INTER-space Privacy\", labelpad=10, fontsize = 24)\n",
    "ax.set_zlim(0,1)\n",
    "ax.set_zticklabels([0,0.2,0.4,0.6,0.8,1.0],fontsize = 16)\n",
    "ax.set_ylabel(\"Max number of planes\", labelpad=10, fontsize = 22)#, offset = 1)\n",
    "ax.set_ylim(0,30)\n",
    "ax.set_yticklabels(np.arange(0,35,5),fontsize = 16)\n",
    "\n",
    "cbar = fig.colorbar(surf, aspect=30, ticks = np.arange(0.0,1.1,0.25))\n",
    "cbar.ax.set_yticklabels(np.arange(0.0,1.1,0.25),fontsize = 16)\n",
    "\n",
    "ax.view_init(25,135);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-3d_env] *",
   "language": "python",
   "name": "conda-env-.conda-3d_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
